{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW6_DE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RumFnRay9oEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b30ff3-8938-40ab-867d-248ba5023615"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n",
            "openjdk-8-jdk-headless is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68_AeFo49pEU"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftRUvQn89-yC"
      },
      "source": [
        "id='1f_9EbnywCj35EBUA32sueigxBjBJwALr'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('War and Peace by Leo Tolstoy (ru).txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpR8DQxm-IRN"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6qPAe12-Q19"
      },
      "source": [
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E-RdW9y-U1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "7723b130-3671-48cf-ea38-92b2544e0f63"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a78474430dc2:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa0298f3f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQRHs49qdDeU"
      },
      "source": [
        "*`ngrok может отработать не с первого раза, повторите при необходимости.`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6LU3RGy-Yag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a76facc-3992-4b6b-99c3-88be7704cd7a"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-29 18:38:02--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.144.219.72, 35.169.70.242, 34.202.43.88, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.144.219.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  21.6MB/s    in 0.6s    \n",
            "\n",
            "2021-05-29 18:38:03 (21.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgte5waWKrpd"
      },
      "source": [
        "Подсчитай кол-во слов в документе \"War and Peace by Leo Tolstoy (ru).txt\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOwFE15Mc1yD"
      },
      "source": [
        "# код\n",
        "import chardet    \n",
        "df = open('./War and Peace by Leo Tolstoy (ru).txt', 'rb').read()\n",
        "result = chardet.detect(df)\n",
        "charenc = result['encoding']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mUF8NYbgdY1I",
        "outputId": "b2abe9bb-1db1-4edd-da50-5ea700c966e0"
      },
      "source": [
        "charenc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'windows-1251'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7AYXXsTKqjm"
      },
      "source": [
        "war_and_peace = spark.read.csv('./War and Peace by Leo Tolstoy (ru).txt', sep='\\n', encoding=charenc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1w-4mySf0sb",
        "outputId": "bf703db1-b091-49d2-935e-b9078ad4b3d5"
      },
      "source": [
        "war_and_peace.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                 _c0|\n",
            "+--------------------+\n",
            "|Война и мир. Книга 1|\n",
            "|Лев Николаевич То...|\n",
            "|      Война и мир #1|\n",
            "|В книгу вошли пер...|\n",
            "|          Том первый|\n",
            "|        Часть первая|\n",
            "|                   I|\n",
            "|– Eh bien, mon pr...|\n",
            "|Так говорила в ию...|\n",
            "|«Si vous n’avez r...|\n",
            "|– Dieu, quelle vi...|\n",
            "|Он говорил на том...|\n",
            "|– Avant tout dite...|\n",
            "|– Как можно быть ...|\n",
            "|– А праздник англ...|\n",
            "|– Я думала, что н...|\n",
            "|– Ежели бы знали,...|\n",
            "|– Ne me tourmente...|\n",
            "|– Как вам сказать...|\n",
            "|Князь Василий гов...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_SE6Dh6g_PX"
      },
      "source": [
        "pattern_punct = '[!@\"“’«»#$%&\\'()*+.,—/:;<=>?^_`{|}~\\[\\]\\d]'\n",
        "war_and_peace = war_and_peace.withColumn('cleaned', regexp_replace('_c0', pattern_punct, ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWvb19Y0izZ5",
        "outputId": "cd98aa2b-c2bd-4439-e6a3-4138a698b120"
      },
      "source": [
        "war_and_peace.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|                 _c0|             cleaned|\n",
            "+--------------------+--------------------+\n",
            "|Война и мир. Книга 1|  Война и мир Книга |\n",
            "|Лев Николаевич То...|Лев Николаевич То...|\n",
            "|      Война и мир #1|        Война и мир |\n",
            "|В книгу вошли пер...|В книгу вошли пер...|\n",
            "|          Том первый|          Том первый|\n",
            "|        Часть первая|        Часть первая|\n",
            "|                   I|                   I|\n",
            "|– Eh bien, mon pr...|– Eh bien mon pri...|\n",
            "|Так говорила в ию...|Так говорила в ию...|\n",
            "|«Si vous n’avez r...|Si vous navez rie...|\n",
            "|– Dieu, quelle vi...|– Dieu quelle vir...|\n",
            "|Он говорил на том...|Он говорил на том...|\n",
            "|– Avant tout dite...|– Avant tout dite...|\n",
            "|– Как можно быть ...|– Как можно быть ...|\n",
            "|– А праздник англ...|– А праздник англ...|\n",
            "|– Я думала, что н...|– Я думала что ны...|\n",
            "|– Ежели бы знали,...|– Ежели бы знали ...|\n",
            "|– Ne me tourmente...|– Ne me tourmente...|\n",
            "|– Как вам сказать...|– Как вам сказать...|\n",
            "|Князь Василий гов...|Князь Василий гов...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PlPyvTCkZhQ"
      },
      "source": [
        "from pyspark.ml.feature import RegexTokenizer\n",
        "regexTokenizer = RegexTokenizer(inputCol='cleaned', outputCol='tokens', pattern=r'\\s+')\n",
        "war_and_peace = regexTokenizer.transform(war_and_peace)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjx1F7GiIvbN",
        "outputId": "fc4c4221-2ea9-415c-e85f-0307df8accf1"
      },
      "source": [
        "war_and_peace.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                 _c0|             cleaned|              tokens|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|Война и мир. Книга 1|  Война и мир Книга |[война, и, мир, к...|\n",
            "|Лев Николаевич То...|Лев Николаевич То...|[лев, николаевич,...|\n",
            "|      Война и мир #1|        Война и мир |     [война, и, мир]|\n",
            "|В книгу вошли пер...|В книгу вошли пер...|[в, книгу, вошли,...|\n",
            "|          Том первый|          Том первый|       [том, первый]|\n",
            "|        Часть первая|        Часть первая|     [часть, первая]|\n",
            "|                   I|                   I|                 [i]|\n",
            "|– Eh bien, mon pr...|– Eh bien mon pri...|[– eh, bien, mon,...|\n",
            "|Так говорила в ию...|Так говорила в ию...|[так, говорила, в...|\n",
            "|«Si vous n’avez r...|Si vous navez rie...|[si, vous, navez,...|\n",
            "|– Dieu, quelle vi...|– Dieu quelle vir...|[– dieu, quelle, ...|\n",
            "|Он говорил на том...|Он говорил на том...|[он, говорил, на,...|\n",
            "|– Avant tout dite...|– Avant tout dite...|[– avant, tout, d...|\n",
            "|– Как можно быть ...|– Как можно быть ...|[– как, можно, бы...|\n",
            "|– А праздник англ...|– А праздник англ...|[– а, праздник, а...|\n",
            "|– Я думала, что н...|– Я думала что ны...|[– я, думала, что...|\n",
            "|– Ежели бы знали,...|– Ежели бы знали ...|[– ежели, бы, зна...|\n",
            "|– Ne me tourmente...|– Ne me tourmente...|[– ne, me, tourme...|\n",
            "|– Как вам сказать...|– Как вам сказать...|[– как, вам, сказ...|\n",
            "|Князь Василий гов...|Князь Василий гов...|[князь, василий, ...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPxe3Olgkh5v",
        "outputId": "f0d3807a-8f5a-4cb2-f7a5-ed3ef6a4b814"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LED8jEklEvg",
        "outputId": "79aafc25-8835-4850-d93b-cfb576f76908"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 4.6MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xsjiRDjkiFw"
      },
      "source": [
        "import pymorphy2\n",
        "from nltk.corpus import stopwords\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "ru_stopwords = stopwords.words('russian')\n",
        "digits = [str(i) for i in range(10)]\n",
        "def preprocess(tokens):\n",
        "    return [morph.normal_forms(word)[0]\n",
        "            for word in tokens\n",
        "                if (word[0] not in digits and\n",
        "                    word not in ru_stopwords)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCXvISJQlJ2L"
      },
      "source": [
        "from pyspark.sql.types import ArrayType, StringType\n",
        "preprocess_udf = udf(preprocess, ArrayType(StringType()))\n",
        "war_and_peace = war_and_peace.withColumn('finished', preprocess_udf('tokens'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gJXkevglJ5i",
        "outputId": "59953a6e-8314-4729-b0af-4e0bd873bd1f"
      },
      "source": [
        "war_and_peace.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                 _c0|             cleaned|              tokens|            finished|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Война и мир. Книга 1|  Война и мир Книга |[война, и, мир, к...| [война, мир, книга]|\n",
            "|Лев Николаевич То...|Лев Николаевич То...|[лев, николаевич,...|[лев, николаевич,...|\n",
            "|      Война и мир #1|        Война и мир |     [война, и, мир]|        [война, мир]|\n",
            "|В книгу вошли пер...|В книгу вошли пер...|[в, книгу, вошли,...|[книга, войти, пе...|\n",
            "|          Том первый|          Том первый|       [том, первый]|            [первый]|\n",
            "|        Часть первая|        Часть первая|     [часть, первая]|     [часть, первый]|\n",
            "|                   I|                   I|                 [i]|                 [i]|\n",
            "|– Eh bien, mon pr...|– Eh bien mon pri...|[– eh, bien, mon,...|[– eh, bien, mon,...|\n",
            "|Так говорила в ию...|Так говорила в ию...|[так, говорила, в...|[говорить, июль, ...|\n",
            "|«Si vous n’avez r...|Si vous navez rie...|[si, vous, navez,...|[si, vous, navez,...|\n",
            "|– Dieu, quelle vi...|– Dieu quelle vir...|[– dieu, quelle, ...|[– dieu, quelle, ...|\n",
            "|Он говорил на том...|Он говорил на том...|[он, говорил, на,...|[говорить, изыска...|\n",
            "|– Avant tout dite...|– Avant tout dite...|[– avant, tout, d...|[– avant, tout, d...|\n",
            "|– Как можно быть ...|– Как можно быть ...|[– как, можно, бы...|[– как, здоровой…...|\n",
            "|– А праздник англ...|– А праздник англ...|[– а, праздник, а...|[– а, праздник, а...|\n",
            "|– Я думала, что н...|– Я думала что ны...|[– я, думала, что...|[– я, думать, нын...|\n",
            "|– Ежели бы знали,...|– Ежели бы знали ...|[– ежели, бы, зна...|[– ежель, знать, ...|\n",
            "|– Ne me tourmente...|– Ne me tourmente...|[– ne, me, tourme...|[– ne, me, tourme...|\n",
            "|– Как вам сказать...|– Как вам сказать...|[– как, вам, сказ...|[– как, сказать –...|\n",
            "|Князь Василий гов...|Князь Василий гов...|[князь, василий, ...|[князь, василий, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zUJpPjwlJ8g"
      },
      "source": [
        "number_of_words = war_and_peace.select(size(war_and_peace.finished)\\\n",
        "                               .name('number_of_words'))\\\n",
        "                               .agg(sum('number_of_words')\\\n",
        "                               .name('number_of_words'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yrO_Ee5rnll",
        "outputId": "b9595183-0e9b-484d-cc40-97bcaabf2b42"
      },
      "source": [
        "number_of_words.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+\n",
            "|number_of_words|\n",
            "+---------------+\n",
            "|         299659|\n",
            "+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSU-TTUvNaON"
      },
      "source": [
        "Необходимо обучить модель используя Spark MLlib (модель на ваш выбор, например Decision Tree) и получить accuracy.\n",
        "Подробнее тут: https://spark.apache.org/docs/latest/ml-classification-regression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJgmIgCzLJTo"
      },
      "source": [
        "id='13yfAoONwq4rS5XrTv3IrcqcFcdgfvK9V'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('mnist-digits-train.txt')\n",
        "\n",
        "id='1VE_9x0LQvOJpHXbXp_RMPl3Q4wRUuOok'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('mnist-digits-test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lPUUuQsQV4F"
      },
      "source": [
        "training = spark.read.format(\"libsvm\") \\\n",
        "  .option(\"numFeatures\", \"784\") \\\n",
        "  .load(\"./mnist-digits-train.txt\")\n",
        "test = spark.read.format(\"libsvm\") \\\n",
        "  .option(\"numFeatures\", \"784\") \\\n",
        "  .load(\"./mnist-digits-test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iy7kv7_3W1o",
        "outputId": "1ac6aca6-f71e-4146-fee6-e6b4db90c5b3"
      },
      "source": [
        "training.show(5)\n",
        "test.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  5.0|(784,[152,153,154...|\n",
            "|  0.0|(784,[127,128,129...|\n",
            "|  4.0|(784,[160,161,162...|\n",
            "|  1.0|(784,[158,159,160...|\n",
            "|  9.0|(784,[208,209,210...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  7.0|(784,[202,203,204...|\n",
            "|  2.0|(784,[94,95,96,97...|\n",
            "|  1.0|(784,[128,129,130...|\n",
            "|  0.0|(784,[124,125,126...|\n",
            "|  4.0|(784,[150,151,159...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKLBBh8b3XuG"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwc5Xe6m_7ds"
      },
      "source": [
        "rf = RandomForestClassifier(labelCol='label', \n",
        "                            featuresCol='features', \n",
        "                            numTrees=500)\n",
        "model = rf.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfuo3PqJABS7",
        "outputId": "5d866231-bdfb-4340-9644-dead78c40bb2"
      },
      "source": [
        "predictions = model.transform(test)\n",
        "predictions.select('label', 'features').show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  7.0|(784,[202,203,204...|\n",
            "|  2.0|(784,[94,95,96,97...|\n",
            "|  1.0|(784,[128,129,130...|\n",
            "|  0.0|(784,[124,125,126...|\n",
            "|  4.0|(784,[150,151,159...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrtgp4NGAHrz",
        "outputId": "90dab022-02a4-4edf-cf26-c90b005d72f3"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol='label', \n",
        "                                              predictionCol='prediction', \n",
        "                                              metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f'accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv-s45P8Oy8Q"
      },
      "source": [
        "Тут лежат данные для решения задач на sql. Необходимо написать код который формирует из данных датафреймы и используя sqlContext написать sql код с решением. Приветствуется наличие нескольких вариантов решения задачи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKMztZ2eOOrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7de1222-2c75-42e8-e01b-4e013a8d5afe"
      },
      "source": [
        "id='1kUIrskM0zNH8u71G9M1BkHjRQYxvgAvh'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('data.zip')\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/regions.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/regions.csv        \n",
            "replace data/departments.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/departments.csv    \n",
            "replace data/jobs.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/jobs.csv           \n",
            "replace data/locations.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/locations.csv      \n",
            "replace data/country.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/country.csv        \n",
            "replace data/employees.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/employees.csv      \n",
            "replace data/job_history.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/job_history.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcVPugjhv_lg"
      },
      "source": [
        "regions = spark.read.csv('./data/regions.csv', header=True, sep='\\t', inferSchema=True)\n",
        "regions.createOrReplaceTempView('regions')\n",
        "\n",
        "departments = spark.read.csv('./data/departments.csv', header=True, sep='\\t', inferSchema=True)\n",
        "departments.createOrReplaceTempView('departments')\n",
        "\n",
        "jobs = spark.read.csv('./data/jobs.csv', header=True, sep='\\t', inferSchema=True)\n",
        "jobs.createOrReplaceTempView('jobs')\n",
        "\n",
        "locations = spark.read.csv('./data/locations.csv', header=True, sep='\\t', inferSchema=True)\n",
        "locations.createOrReplaceTempView('locations')\n",
        "\n",
        "country = spark.read.csv('./data/country.csv', header=True, sep='\\t', inferSchema=True)\n",
        "country.createOrReplaceTempView('country')\n",
        "\n",
        "employees = spark.read.csv('./data/employees.csv', header=True, sep='\\t', inferSchema=True)\n",
        "employees.createOrReplaceTempView('employees')\n",
        "\n",
        "job_history = spark.read.csv('./data/job_history.csv', header=True, sep='\\t', inferSchema=True)\n",
        "job_history.createOrReplaceTempView('job_history')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85l1H2gowFzc",
        "outputId": "d45a48d8-dab9-4acc-c1a9-d08213601974"
      },
      "source": [
        "# посмотрим, что находится в таблицах\n",
        "regions.show(5)\n",
        "departments.show(5)\n",
        "jobs.show(5)\n",
        "locations.show(5)\n",
        "country.show(5)\n",
        "employees.show(5)\n",
        "job_history.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+\n",
            "|REGION_ID|         REGION_NAME|\n",
            "+---------+--------------------+\n",
            "|        1|              Europe|\n",
            "|        2|            Americas|\n",
            "|        3|                Asia|\n",
            "|        4|Middle East and A...|\n",
            "+---------+--------------------+\n",
            "\n",
            "+-------------+---------------+----------+-----------+\n",
            "|DEPARTMENT_ID|DEPARTMENT_NAME|MANAGER_ID|LOCATION_ID|\n",
            "+-------------+---------------+----------+-----------+\n",
            "|           10| Administration|       200|       1700|\n",
            "|           20|      Marketing|       201|       1800|\n",
            "|           30|     Purchasing|       114|       1700|\n",
            "|           40|Human Resources|       203|       2400|\n",
            "|           50|       Shipping|       121|       1500|\n",
            "+-------------+---------------+----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+--------------------+----------+----------+\n",
            "|    JOB_ID|           JOB_TITLE|MIN_SALARY|MAX_SALARY|\n",
            "+----------+--------------------+----------+----------+\n",
            "|   AD_PRES|           President|     20080|     40000|\n",
            "|     AD_VP|Administration Vi...|     15000|     30000|\n",
            "|   AD_ASST|Administration As...|      3000|      6000|\n",
            "|    FI_MGR|     Finance Manager|      8200|     16000|\n",
            "|FI_ACCOUNT|          Accountant|      4200|      9000|\n",
            "+----------+--------------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+--------------------+-----------+---------+----------------+----------+\n",
            "|LOCATION_ID|      STREET_ADDRESS|POSTAL_CODE|     CITY|  STATE_PROVINCE|COUNTRY_ID|\n",
            "+-----------+--------------------+-----------+---------+----------------+----------+\n",
            "|       1000|1297 Via Cola di Rie|      00989|     Roma|            null|        IT|\n",
            "|       1100|93091 Calle della...|      10934|   Venice|            null|        IT|\n",
            "|       1200|    2017 Shinjuku-ku|       1689|    Tokyo|Tokyo Prefecture|        JP|\n",
            "|       1300|     9450 Kamiya-cho|       6823|Hiroshima|            null|        JP|\n",
            "|       1400| 2014 Jabberwocky Rd|      26192|Southlake|           Texas|        US|\n",
            "+-----------+--------------------+-----------+---------+----------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+------------+---------+\n",
            "|COUNTRY_ID|COUNTRY_NAME|REGION_ID|\n",
            "+----------+------------+---------+\n",
            "|        AR|   Argentina|        2|\n",
            "|        AU|   Australia|        3|\n",
            "|        BE|     Belgium|        1|\n",
            "|        BR|      Brazil|        2|\n",
            "|        CA|      Canada|        2|\n",
            "+----------+------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+----------+---------+--------+------------+---------+-------+------+--------------+----------+-------------+\n",
            "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE| JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
            "+-----------+----------+---------+--------+------------+---------+-------+------+--------------+----------+-------------+\n",
            "|        100|    Steven|     King|   SKING|515.123.4567| 17.06.03|AD_PRES| 24000|          null|      null|           90|\n",
            "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568| 21.09.05|  AD_VP| 17000|          null|       100|           90|\n",
            "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569| 13.01.01|  AD_VP| 17000|          null|       100|           90|\n",
            "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567| 03.01.06|IT_PROG|  9000|          null|       102|           60|\n",
            "|        104|     Bruce|    Ernst|  BERNST|590.423.4568| 21.05.07|IT_PROG|  6000|          null|       103|           60|\n",
            "+-----------+----------+---------+--------+------------+---------+-------+------+--------------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+----------+--------+----------+-------------+\n",
            "|EMPLOYEE_ID|START_DATE|END_DATE|    JOB_ID|DEPARTMENT_ID|\n",
            "+-----------+----------+--------+----------+-------------+\n",
            "|        102|  13.01.01|24.07.06|   IT_PROG|           60|\n",
            "|        101|  21.09.97|27.10.01|AC_ACCOUNT|          110|\n",
            "|        101|  28.10.01|15.03.05|    AC_MGR|          110|\n",
            "|        201|  17.02.04|19.12.07|    MK_REP|           20|\n",
            "|        114|  24.03.06|31.12.07|  ST_CLERK|           50|\n",
            "+-----------+----------+--------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v43K2fDAjUYb"
      },
      "source": [
        "Кто получает больше всего? Кто меньше всего?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm15EW8znWDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4a2ca2-9873-49f8-b28f-ce80e002a6cc"
      },
      "source": [
        "# код\n",
        "# получает больше всего\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select first_name, last_name, salary\n",
        "    from employees\n",
        "    where salary = (select max(salary) \n",
        "                    from employees) \n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+------+\n",
            "|first_name|last_name|salary|\n",
            "+----------+---------+------+\n",
            "|    Steven|     King| 24000|\n",
            "+----------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtepXqNO6M0a",
        "outputId": "7026c550-b0fd-4a51-bf30-4e39d0c65885"
      },
      "source": [
        "# код\n",
        "# получает меньше всего\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select first_name, last_name, salary\n",
        "    from employees\n",
        "    where salary = (select min(salary) \n",
        "                    from employees) \n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+------+\n",
            "|first_name|last_name|salary|\n",
            "+----------+---------+------+\n",
            "|        TJ|    Olson|  2100|\n",
            "+----------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg8-rkFlkMqm"
      },
      "source": [
        "Выведете топ 5 по зарплате."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMzJ_tJhnWuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97aeb00-13f3-4936-b18d-b5015bb20a42"
      },
      "source": [
        "# код\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select first_name, last_name, salary\n",
        "    from employees\n",
        "    order by salary desc\n",
        "    limit 5 \n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+------+\n",
            "|first_name|last_name|salary|\n",
            "+----------+---------+------+\n",
            "|    Steven|     King| 24000|\n",
            "|     Neena|  Kochhar| 17000|\n",
            "|       Lex|  De Haan| 17000|\n",
            "|      John|  Russell| 14000|\n",
            "|     Karen| Partners| 13500|\n",
            "+----------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfBpDVYwkM7K"
      },
      "source": [
        "Сколько всего регионов? Сколько работников в каждом регионе?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2d2AiBknYSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45648be7-4490-486d-a33c-f40e5d3d8eac"
      },
      "source": [
        "# код\n",
        "# сколько всего регионов\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select count(*) as number_of_regions\n",
        "    from regions\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|number_of_regions|\n",
            "+-----------------+\n",
            "|                4|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSXBYUlz7S2N",
        "outputId": "279dacc4-7315-46fc-bc6f-39606a271585"
      },
      "source": [
        "# какие именно это регионы\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select region_id, region_name\n",
        "    from regions\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+\n",
            "|region_id|         region_name|\n",
            "+---------+--------------------+\n",
            "|        1|              Europe|\n",
            "|        2|            Americas|\n",
            "|        3|                Asia|\n",
            "|        4|Middle East and A...|\n",
            "+---------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caabRkNp7S--",
        "outputId": "c33b8631-2912-44f4-831a-3cb027f923c3"
      },
      "source": [
        "# сколько работников в каждом регионе\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select r.region_id, count(e.employee_id) as number_of_employees\n",
        "    from employees e\n",
        "    join departments d \n",
        "      on e.department_id = d.department_id\n",
        "    join locations l \n",
        "      on d.location_id = l.location_id\n",
        "    join country c \n",
        "      on l.country_id = c.country_id\n",
        "    join regions r \n",
        "      on c.region_id = r.region_id\n",
        "    group by r.region_id\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-------------------+\n",
            "|region_id|number_of_employees|\n",
            "+---------+-------------------+\n",
            "|        1|                 36|\n",
            "|        2|                 70|\n",
            "+---------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOY2unJ8kNXz"
      },
      "source": [
        "Выведете всех работников из Китая."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lhj9GAwnZgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e67f297-9642-46ec-a14a-df2b4d23a9c6"
      },
      "source": [
        "# код\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select first_name, last_name\n",
        "    from employees e\n",
        "    join departments d \n",
        "      on e.department_id = d.department_id\n",
        "    join locations l \n",
        "      on d.location_id = l.location_id\n",
        "    join country c \n",
        "      on l.country_id = c.country_id\n",
        "    where country_name = 'China'\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|first_name|last_name|\n",
            "+----------+---------+\n",
            "+----------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Nc8F-6kNR7"
      },
      "source": [
        "Укажите самую высокооплачиваемою должность."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZNAohM-naSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a87df0-2a04-4ebe-e736-7d302be3609d"
      },
      "source": [
        "# код\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select job_title, max_salary\n",
        "    from jobs\n",
        "    where max_salary = (select max(max_salary) \n",
        "                        from jobs) \n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----------+\n",
            "|job_title|max_salary|\n",
            "+---------+----------+\n",
            "|President|     40000|\n",
            "+---------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzenJwUnkNL8"
      },
      "source": [
        "Выведете всех работников связанных с ИТ. Выведете их менеджеров. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eogYiLjXna3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fdeb622-d4b6-4fd1-df32-e4401be8c303"
      },
      "source": [
        "# код\n",
        "# вывести всех работников, связанных с ИТ\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select first_name, last_name\n",
        "    from employees e\n",
        "    join departments d \n",
        "      on e.department_id = d.department_id\n",
        "    where department_name like '%IT%'\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|first_name|last_name|\n",
            "+----------+---------+\n",
            "| Alexander|   Hunold|\n",
            "|     Bruce|    Ernst|\n",
            "|     David|   Austin|\n",
            "|     Valli|Pataballa|\n",
            "|     Diana|  Lorentz|\n",
            "+----------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGDQ9QeCrT8z",
        "outputId": "cfa526dc-a735-4b44-9a5e-56894c9a3e2a"
      },
      "source": [
        "# вывести менеджеров работников, связанных с ИТ (вариант 1)\n",
        "# если нужна информация как о менеджерах, так и о работниках из ИТ\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    with managers_and_employees as (\n",
        "      select \n",
        "        m.employee_id as manager_id, \n",
        "        m.first_name as manager_first_name,\n",
        "        m.last_name as manager_last_name,\n",
        "        e.employee_id as employee_id, \n",
        "        e.first_name as employee_first_name, \n",
        "        e.last_name as employee_last_name, \n",
        "        e.department_id\n",
        "      from employees e\n",
        "      left join employees m\n",
        "      where  m.employee_id = e.manager_id\n",
        "    )\n",
        "\n",
        "    select \n",
        "      me.manager_id,\n",
        "      me.manager_first_name,\n",
        "      me.manager_last_name,\n",
        "      me.employee_id,\n",
        "      me.employee_first_name,\n",
        "      me.employee_last_name,\n",
        "      d.department_name as employee_department_name\n",
        "    from managers_and_employees me\n",
        "    join departments d \n",
        "      on me.department_id = d.department_id\n",
        "    where department_name like '%IT%'\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------------------+-----------------+-----------+-------------------+------------------+------------------------+\n",
            "|manager_id|manager_first_name|manager_last_name|employee_id|employee_first_name|employee_last_name|employee_department_name|\n",
            "+----------+------------------+-----------------+-----------+-------------------+------------------+------------------------+\n",
            "|       102|               Lex|          De Haan|        103|          Alexander|            Hunold|                      IT|\n",
            "|       103|         Alexander|           Hunold|        104|              Bruce|             Ernst|                      IT|\n",
            "|       103|         Alexander|           Hunold|        105|              David|            Austin|                      IT|\n",
            "|       103|         Alexander|           Hunold|        106|              Valli|         Pataballa|                      IT|\n",
            "|       103|         Alexander|           Hunold|        107|              Diana|           Lorentz|                      IT|\n",
            "+----------+------------------+-----------------+-----------+-------------------+------------------+------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTOGnUyxx6ye",
        "outputId": "60cb8722-40e3-4d00-a8b2-688ab5411944"
      },
      "source": [
        "# вывести менеджеров работников, связанных с ИТ (вариант 2)\n",
        "# если нужна информация лишь о личности менеджеров\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    with managers_and_employees as (\n",
        "      select \n",
        "        m.employee_id as manager_id, \n",
        "        m.first_name as manager_first_name,\n",
        "        m.last_name as manager_last_name,\n",
        "        e.employee_id as employee_id, \n",
        "        e.first_name as employee_first_name, \n",
        "        e.last_name as employee_last_name, \n",
        "        e.department_id\n",
        "      from employees e\n",
        "      left join employees m\n",
        "      where  m.employee_id = e.manager_id\n",
        "    )\n",
        "\n",
        "    select \n",
        "      distinct me.manager_id,\n",
        "      me.manager_first_name,\n",
        "      me.manager_last_name\n",
        "    from managers_and_employees me\n",
        "    join departments d \n",
        "      on me.department_id = d.department_id\n",
        "    where department_name like '%IT%'\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------------------+-----------------+\n",
            "|manager_id|manager_first_name|manager_last_name|\n",
            "+----------+------------------+-----------------+\n",
            "|       103|         Alexander|           Hunold|\n",
            "|       102|               Lex|          De Haan|\n",
            "+----------+------------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvpCoeYPmLTW"
      },
      "source": [
        "Выведете имя и фамилию работника, его текущую и предыдущую должности и сколько полных недель и дней прошло с момент изменения. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkCvyzkVnbo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394cbc2c-9791-4d9f-8dfe-05f44db7c9fd"
      },
      "source": [
        "# код \n",
        "# не совсем было понятно, что считать разницей, в итоге получилось так:\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    with cte as (\n",
        "      select \n",
        "        employee_id,\n",
        "        job_id,\n",
        "        to_date(end_date, 'dd.mm.yy') as end_date_,\n",
        "        row_number() over(partition by employee_id order by to_date(end_date, 'dd.mm.yy') desc) as rank\n",
        "      from job_history\n",
        "    )\n",
        "\n",
        "    select \n",
        "      --e.employee_id as employee_id,\n",
        "      e.first_name as first_name,\n",
        "      e.last_name as last_name,\n",
        "      e.job_id as current_job_id,\n",
        "      cte.job_id as previous_job_id,\n",
        "      --cte.end_date_ as end_date,\n",
        "      --to_date(e.hire_date, 'dd.mm.yy') as hire_date,\n",
        "      datediff(cte.end_date_, to_date(e.hire_date, 'dd.mm.yy')) as days,\n",
        "      ceil(datediff(cte.end_date_, to_date(e.hire_date, 'dd.mm.yy')) / 7) as weeks\n",
        "    from employees e\n",
        "    join cte\n",
        "      on e.employee_id = cte.employee_id \n",
        "      and cte.rank = 1\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+--------------+---------------+----+-----+\n",
            "|first_name|last_name|current_job_id|previous_job_id|days|weeks|\n",
            "+----------+---------+--------------+---------------+----+-----+\n",
            "|     Neena|  Kochhar|         AD_VP|         AC_MGR|  -6|    0|\n",
            "|       Lex|  De Haan|         AD_VP|        IT_PROG|1837|  263|\n",
            "|       Den| Raphaely|        PU_MAN|       ST_CLERK|1850|  265|\n",
            "|     Payam| Kaufling|        ST_MAN|       ST_CLERK|1491|  213|\n",
            "|  Jonathon|   Taylor|        SA_REP|         SA_MAN| 372|   54|\n",
            "|  Jennifer|   Whalen|       AD_ASST|     AC_ACCOUNT|1110|  159|\n",
            "|   Michael|Hartstein|        MK_MAN|         MK_REP|1098|  157|\n",
            "+----------+---------+--------------+---------------+----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOBhGAaanC0e"
      },
      "source": [
        "Выведете уникальные телефонные номера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05BrXyrsncKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753429a4-0350-4f23-ec3a-1c3ea69ff0ca"
      },
      "source": [
        "# код\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select distinct phone_number\n",
        "    from employees\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|      phone_number|\n",
            "+------------------+\n",
            "|011.44.1344.429018|\n",
            "|      515.127.4566|\n",
            "|      515.127.4564|\n",
            "|011.44.1344.429278|\n",
            "|      515.123.4569|\n",
            "|      650.124.1434|\n",
            "|      650.123.2234|\n",
            "|011.44.1344.498718|\n",
            "|      650.127.1634|\n",
            "|      515.127.4561|\n",
            "|011.44.1345.629268|\n",
            "|      515.127.4562|\n",
            "|011.44.1644.429264|\n",
            "|011.44.1644.429262|\n",
            "|      650.501.1876|\n",
            "|      650.127.1834|\n",
            "|011.44.1343.529268|\n",
            "|011.44.1644.429265|\n",
            "|      515.123.8181|\n",
            "|      650.507.9833|\n",
            "+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdf1VBv3nMR-"
      },
      "source": [
        "Есть ли сотрудники с одинаковыми фамилиями и сколько их."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apTLX1o6jy6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f5d132-01a1-4624-880f-b7ae22b09eb1"
      },
      "source": [
        "# код\n",
        "# есть ли сотрудники с одинаковыми фамилиями\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select last_name, count(*) as number_of_last_names\n",
        "    from employees\n",
        "    group by last_name\n",
        "    having number_of_last_names > 1\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+\n",
            "|last_name|number_of_last_names|\n",
            "+---------+--------------------+\n",
            "|    Smith|                   2|\n",
            "|     King|                   2|\n",
            "|Cambrault|                   2|\n",
            "|   Taylor|                   2|\n",
            "+---------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql99e-Ffesuo",
        "outputId": "686929ad-b7d5-4488-a5f2-f048f37501e4"
      },
      "source": [
        "# общее число сотрудников с одинаковыми фамилиями\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    with cte as (\n",
        "      select count(*) as number_of_last_names\n",
        "      from employees\n",
        "      group by last_name\n",
        "      having number_of_last_names > 1\n",
        "    )\n",
        "\n",
        "    select sum(*) as number_of_people_with_similar_last_names from cte\n",
        "    \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------+\n",
            "|number_of_people_with_similar_last_names|\n",
            "+----------------------------------------+\n",
            "|                                       8|\n",
            "+----------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}